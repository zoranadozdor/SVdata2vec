# data
feeder: feeder.feeder.Feeder
train_feeder_args:
  multimodal: True
  dataset: "ntu"
  data_prefix : SVDATA2VEC/data/ntu/RGB_videos/nturgb+d_videos_c #path to video files
  split: 'xsub_train'
  test_mode: False
  ann_file : SVDATA2VEC/data/ntu/ntu120_hrnet.pkl #path to annotation file
  pipeline: 
    - type: "MMUniformSampleFrames"
      clip_len: 
        RGB: 40
        Pose: 40
      num_clips: 1
    - type: "MMDecode"
    - type: "MMCompact"
      padding: 0.1
      hw_ratio: 1.
      allow_imgpad: True
    - type: Resize
      scale: !!python/tuple
        - 256
        - 256
      keep_ratio: false

    - type: RandomResizedCrop
      area_range: !!python/tuple
        - 0.56
        - 1.0

    - type: Resize
      scale: !!python/tuple
        - 224
        - 224
      keep_ratio: false
    
    - type: Flip
      flip_ratio: 0.5
      left_kp: [1, 3, 5, 7, 9, 11, 13, 15]
      right_kp: [2, 4, 6, 8, 10, 12, 14, 16]

    - type: Normalize
      mean:
        - 123.675
        - 116.28
        - 103.53
      std:
        - 58.395
        - 57.12
        - 57.375
      to_bgr: false

    - type: FormatShape
      input_format: NCTHW

    - type: Collect
      keys:
        - imgs
        - keypoint
        - label
      meta_keys: []

    - type: ToTensor
      keys:
        - imgs
        - keypoint
        - label


# model
model: model_svdata2vec.transformer.Transformer
model_args:
  dim_in: 2
  dim_feat: 256
  decoder_dim_feat: 256
  depth: 8
  decoder_depth: 3
  num_heads: 8
  mlp_ratio: 4
  num_frames: 40
  num_joints: 17
  patch_size: 17
  t_patch_size: 1
  qkv_bias: True
  qk_scale: None
  drop_rate: 0.
  attn_drop_rate: 0.
  drop_path_rate: 0.
  block_norm_first: True #is normalization in attention block before or after residual
  target_ffn: False #set target to ffn layer output
  #ema params
  num_layers_for_target: 8
  ema_decay: 0.999
  ema_end_decay: 0.99999
  ema_anneal_end_step: 50000
  instance_norm_target_layer: True
  batch_norm_target_layer: False
  layer_norm_target_layer: False
  layer_norm_targets: False
  instance_norm_targets: False

# training 
epochs: 400  
warmup_epochs: 20
batch_size: 32
lr: 1e-3
min_lr: 5e-4
weight_decay: 0.05
mask_ratio: 0.7
